{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp15ZJ_qFUlQ"
      },
      "source": [
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
        "from numpy import append\n",
        "import seaborn as sns \n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "import statistics\n",
        "from numpy import asarray\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from matplotlib import pyplot\n",
        "from numpy import zeros\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import statsmodels\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TI0zyxfSIX34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fatzjrmeXZ2y"
      },
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUVEy8yAIuAc"
      },
      "source": [
        "feature_list = ['Random Forest', 'Bagging', 'Extra Trees', 'Linear Regressor', 'Elastic Net', 'Ridge', 'Lasso', 'Decision Tree', 'K Neighnours', 'Vector Auto Regression', 'VARMAX']\n",
        "zero_data = zeros(shape=(4,len(feature_list)))\n",
        "errors = pd.DataFrame(zero_data, columns=feature_list)\n",
        "keys =['MAE', 'MSE', 'RMSE', 'MSLE']\n",
        "errors.rename(index={0:keys[0],1:keys[1], 2:keys[2], 3:keys[3]}, inplace=True)\n",
        "errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCCUukACT9j0"
      },
      "source": [
        "data1 = read_csv('/content/NO2 Data Final.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-_Nz3VuXoPw"
      },
      "source": [
        "date = data1['date']\n",
        "data1 = data1.drop(['date'], axis=1)\n",
        "cols_o = data1.columns\n",
        "data1['date']=date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEWRAkIBXvDc"
      },
      "source": [
        "data1 = data1.drop(['date'], axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8FYhE_jYC5o"
      },
      "source": [
        "dates_May_Apr = asarray(date[len(date)-61:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlBqGSOdYMPx"
      },
      "source": [
        "dates_May_Apr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2BGsbjcTVWU"
      },
      "source": [
        "#data1 = data1.drop(['Unnamed: 0'], axis=1)\n",
        "values = data1.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQEk-cMYIzL9"
      },
      "source": [
        "# **Statistical Forecasting Models**# \n",
        "\n",
        "\n",
        "1.   Vector Auto Regression\n",
        "2.   Vector Autoregression Moving-Average\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfOGvxRYEBrc"
      },
      "source": [
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "from statsmodels.tsa.statespace.varmax import VARMAX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys55PsSW1Bui"
      },
      "source": [
        "train = data1[:int(0.8*(len(data1)))]\n",
        "valid = data1[int(0.8*(len(data1))):]\n",
        "cols = data1.columns\n",
        "history = asarray(train)\n",
        "prediction = []\n",
        "#fit the model\n",
        "\n",
        "for i in range(len(valid)):\n",
        "    model = VAR(endog=history)\n",
        "    model_fit = model.fit()\n",
        "    prediction_= model_fit.forecast(model_fit.y, 1)\n",
        "    prediction.append(prediction_)\n",
        "    valid_one = asarray(valid.iloc[i]).reshape(1,64)\n",
        "    history = append(history, valid_one, axis = 0)\n",
        "# make prediction on validation\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdKz00z_PoBA"
      },
      "source": [
        "prediction = asarray(prediction)\n",
        "prediction = prediction.reshape(len(valid),64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M9JM9_KVn4D"
      },
      "source": [
        "pred = asarray(prediction)\n",
        "valid = asarray(valid)\n",
        "mse = mean_squared_error(pred, valid)\n",
        "mae = mean_absolute_error(pred, valid)\n",
        "mape = mean_absolute_percentage_error(valid,pred)\n",
        "rmse = sqrt(mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su84cnQy99L9"
      },
      "source": [
        "name = 'VARMAX'\n",
        "print(name,  ':Mean Absolute Error (Nitrogen Dioxide):', mae)\n",
        "print(name,  ':Mean Squared Error (Nitorgen Dioxide):', mse)\n",
        "print(name,  ':Root Mean Squared Error (Nitrogen Dioxide):', rmse)\n",
        "print(name,  ':Mean Absolue Percentage Error (Nitrogen Dioxide):', mape)\n",
        "\n",
        "errors[name]['MAE']=mae\n",
        "errors[name]['MSE']=mse\n",
        "errors[name]['RMSE']=rmse\n",
        "errors[name]['MLSE']=0\n",
        "\n",
        "predic = pred[11,:]\n",
        "predic = predic.reshape(8,8)\n",
        "predic = predic.astype('float')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test = valid[11,:]\n",
        "test = test.reshape(8,8)\n",
        "test = test.astype(float)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(test)\n",
        "plt.title('Expected')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(predic)\n",
        "plt.title('Predicted')\n",
        "\n",
        "#fig.subplots_adjust(right=0.8)\n",
        "cbar = plt.colorbar()\n",
        "cbar.set_label('Nitrogen Dioxide (ug/m^3)',size=8)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(dates_May_Apr, valid[len(valid)-61:,54], label='Expected')\n",
        "plt.plot(dates_May_Apr,pred[len(pred)-61:,54], label='Predicted')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Nitrogen Dioxide (ug/m^3)')\n",
        "plt.legend()\n",
        "plt.title('VECTOR AUTO REGRESSION')\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(25, 5)\n",
        "fig.savefig('test2png.png', dpi=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4rDRsxwFUN6"
      },
      "source": [
        "# **Data Preparation for Supervised Learning Problem**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7buI_7LNC0X"
      },
      "source": [
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\t\"\"\"\n",
        "\tFrame a time series as a supervised learning dataset.\n",
        "\tArguments:\n",
        "\t\tdata: Sequence of observations as a list or NumPy array.\n",
        "\t\tn_in: Number of lag observations as input (X).\n",
        "\t\tn_out: Number of observations as output (y).\n",
        "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
        "\tReturns:\n",
        "\t\tPandas DataFrame of series framed for supervised learning.\n",
        "\t\"\"\"\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ2LyVNvWfB-"
      },
      "source": [
        "len(values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k6UWWO0QuAz"
      },
      "source": [
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "len(cols)-64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEbIAFiOubsb"
      },
      "source": [
        "cols = data.columns\n",
        "from sklearn.base import clone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv6WzfDdSvQ4"
      },
      "source": [
        "def predictions_no_walk(o_data, data, name, index, model):\n",
        "  predictions = []\n",
        "  #train = data.iloc[0:int(0.80*len(data))]\n",
        "  #test = data.iloc[int(0.80*len(data)):]\n",
        "  x_data = data.iloc[:][cols[0:len(cols)-15*64]]\n",
        "  y_data = data.iloc[:][cols[len(cols)-15*64:]]\n",
        "  \n",
        "  model = clone(model)\n",
        "  #model.fit(x_data, y_data)\n",
        "  #model.fit(train_x_a, train_y_a)\n",
        "  #history = train\n",
        "\t# step over each time-step in the test set\n",
        "  for i in range(2):\n",
        "\n",
        "    model.fit(x_data, y_data)\n",
        "    yhat = model.predict([x_data.iloc[-1]])\n",
        "    yhat = yhat.reshape(15,64)\n",
        "    o_data = append(o_data, yhat, axis=0)\n",
        "    #o_data.append(yhat)\n",
        "    u_data = series_to_supervised(o_data, 30, 15)\n",
        "    x_data = u_data.iloc[:][cols[0:len(cols)-15*64]]\n",
        "    y_data = u_data.iloc[:][cols[len(cols)-15*64:]]\n",
        "\t\t# store forecast in list of predictions\n",
        "    predictions.append(yhat)\n",
        "\n",
        "  \n",
        "  predictions = asarray(predictions)\n",
        "  predictions = predictions.reshape(2,64*15)\n",
        "  predic_64 =zeros((1,64))\n",
        "  #predic_64 = asarray(predic_64)\n",
        "  for i in range(0,len(predictions)):\n",
        "     pred_temp = predictions[i].reshape(15,64)\n",
        "     predic_64 = append(predic_64, pred_temp, axis=0)\n",
        "  #mae = asarray(test_y)\n",
        "  #error = mean_absolute_error(np.asrray(test_y), predictions)\n",
        "  pred = DataFrame(predic_64)\n",
        "  return  predic_64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvP8fQC40fe"
      },
      "source": [
        "# walk-forward validation for univariate data\n",
        "def walk_forward_validation(data, name,index, model):\n",
        "  predictions = []\n",
        "  train = data.iloc[0:int(0.80*len(data))]\n",
        "  test = data.iloc[int(0.80*len(data)):]\n",
        "  x_data = data.iloc[:][cols[0:192]]\n",
        "  y_data = data.iloc[:][cols[192:]]\n",
        "  \n",
        "  test_x = x_data.iloc[int(0.80*len(x_data)):]\n",
        "  test_y = y_data.iloc[int(0.80*len(y_data)):]\n",
        "\n",
        "  #train_x = train.iloc[:][cols[0:192]]\n",
        "  #train_y = train.iloc[:][cols[192:]]\n",
        "  #train_x_a= asarray(train_x)\n",
        "  #train_y_a = asarray(train_y)\n",
        "  model = clone(model)\n",
        "  #model.fit(train_x_a, train_y_a)\n",
        "  history = train\n",
        "\t# step over each time-step in the test set\n",
        "  for i in range(len(test)):\n",
        "    testX, testy = test_x.iloc[i], test_y.iloc[i]\n",
        "\t\t# fit model on history and make a prediction\n",
        "    train_x = history.iloc[:][cols[0:192]]\n",
        "    train_y = history.iloc[:][cols[192:]]\n",
        "    train_x_a= asarray(train_x)\n",
        "    train_y_a = asarray(train_y)\n",
        "    model.fit(train_x_a, train_y_a)\n",
        "    yhat = model.predict([testX])\n",
        "\t\t# store forecast in list of predictions\n",
        "    predictions.append(yhat)\n",
        "\t\t# add actual observation to history for the next loop\n",
        "    history.append(test.iloc[i])\n",
        "\t\t# summarize progress\n",
        "    #print('Predicted:', asarray(yhat), 'Expected:', asarray(test_y.iloc[i]))\n",
        "\t# estimate prediction error\n",
        "  \n",
        "  predictions = asarray(predictions)\n",
        "  predictions = predictions.reshape(len(test),64)\n",
        "  mae = asarray(test_y)\n",
        "  #error = mean_absolute_error(np.asrray(test_y), predictions)\n",
        "  pred = DataFrame(predictions)\n",
        "  pred.to_csv('NO2_predictions.csv')\n",
        "\n",
        "  maes = mean_absolute_error(mae, predictions)\n",
        "  mse = mean_squared_error(mae, predictions)\n",
        "  rmse = sqrt(mse)\n",
        "  mape = mean_absolute_percentage_error(mae,pred)\n",
        "  if name != 'Linear Regressor' and name!= 'Ridge CV':\n",
        "      msle = mean_squared_log_error(predictions, mae)\n",
        "  else:\n",
        "      msle = None\n",
        "\n",
        "  print(name,  ':Mean Absolute Error (Nitrogen Dioxide):', maes)\n",
        "  print(name,  ':Mean Squared Error (Nitrogen Dioxide):', mse)\n",
        "  print(name,  ':Root Mean Squared Error (Nitrogen Dioxide):', rmse)\n",
        "  print(name,  ':Mean Absolute Percentage Error (Nitrogen Dioxide):', mape)\n",
        "\n",
        "  if name != 'Linear Regressor' and name!= 'Ridge CV':\n",
        "      print(name,  ':Mean Squared Logarithmic Error (Nitrogen Dioxide):', msle)\n",
        "\n",
        "  expected = mae[index].reshape(8,8)\n",
        "  predicted = predictions[index].reshape(8,8)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(expected)\n",
        "  plt.title('Expected')\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(predicted)\n",
        "  plt.title('Predicted')\n",
        "  plt.show()\n",
        "  return  mape,maes, mse, rmse, msle, predictions, mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IAnfjcmRfG1"
      },
      "source": [
        "# walk-forward validation for univariate data\n",
        "def walk_forward_validation(data, name, index, model):\n",
        "  predictions = []\n",
        "  train = data.iloc[0:int(0.998*len(data))]\n",
        "  test = data.iloc[int(0.998*len(data)):]\n",
        "  x_data = data.iloc[:][cols[0:len(cols)-15*64]]\n",
        "  y_data = data.iloc[:][cols[len(cols)-15*64:]]\n",
        "  #cols[0:len(cols)-15*64]\n",
        "  test_x = x_data.iloc[int(0.998*len(x_data)):]\n",
        "  test_y = y_data.iloc[int(0.998*len(y_data)):]\n",
        "\n",
        "  #train_x = train.iloc[:][cols[0:192]]\n",
        "  #train_y = train.iloc[:][cols[192:]]\n",
        "  #train_x_a= asarray(train_x)\n",
        "  #train_y_a = asarray(train_y)\n",
        "  model = clone(model)\n",
        "  #model.fit(train_x_a, train_y_a)\n",
        "  history = train\n",
        "\t# step over each time-step in the test set\n",
        "  for i in range(len(test)):\n",
        "    testX, testy = test_x.iloc[i], test_y.iloc[i]\n",
        "\t\t# fit model on history and make a prediction\n",
        "    train_x = history.iloc[:][cols[0:len(cols)-15*64]]\n",
        "    train_y = history.iloc[:][cols[len(cols)-15*64:]]\n",
        "    train_x_a= asarray(train_x)\n",
        "    train_y_a = asarray(train_y)\n",
        "    model.fit(train_x_a, train_y_a)\n",
        "    yhat = model.predict([testX])\n",
        "\t\t# store forecast in list of predictions\n",
        "    predictions.append(yhat)\n",
        "\t\t# add actual observation to history for the next loop\n",
        "    history.append(test.iloc[i])\n",
        "\t\t# summarize progress\n",
        "    #print('Predicted:', asarray(yhat), 'Expected:', asarray(test_y.iloc[i]))\n",
        "\t# estimate prediction error\n",
        "  test_y = asarray(test_y)\n",
        "  test_y = test_y.reshape(len(test_y), 15*64)\n",
        "  predictions = asarray(predictions).reshape(len(predictions), 15*64)\n",
        "  predic_64 =zeros((1,64))\n",
        "  y_64=zeros((1,64))\n",
        "  for i in range(0,len(predictions)):\n",
        "     pred_temp = predictions[i].reshape(15,64)\n",
        "     y_temp = test_y[i].reshape(15,64)\n",
        "     predic_64 = append(predic_64, pred_temp, axis=0)\n",
        "     y_64=append(y_64, y_temp, axis=0)\n",
        "  #predictions = asarray(predictions)\n",
        "  #predictions = predictions.reshape(len(test),64)\n",
        "  \n",
        "  #error = mean_absolute_error(np.asrray(test_y), predictions)\n",
        "  pred = DataFrame(predic_64)\n",
        "  pred.to_csv('NO2_predictions.csv')\n",
        "  \n",
        "  maes = mean_absolute_error(test_y, predictions)\n",
        "  mse = mean_squared_error(test_y, predictions)\n",
        "  rmse = sqrt(mse)\n",
        "  mape = mean_absolute_percentage_error(test_y,predictions)\n",
        "  if name != 'Linear Regressor' and name!= 'Ridge CV':\n",
        "      msle = mean_squared_log_error(predictions, test_y)\n",
        "  else:\n",
        "      msle = None\n",
        "\n",
        "  print(name,  ':Mean Absolute Error (Nitrogen Dioxide):', maes)\n",
        "  print(name,  ':Mean Squared Error (Nitrogen Dioxide):', mse)\n",
        "  print(name,  ':Root Mean Squared Error (Nitrogen Dioxide):', rmse)\n",
        "  print(name,  ':Mean Absolute Percentage Error (Nitrogen Dioxide):', mape)\n",
        "\n",
        "  if name != 'Linear Regressor' and name!= 'Ridge CV':\n",
        "      print(name,  ':Mean Squared Logarithmic Error (Nitrogen Dioxide):', msle)\n",
        "\n",
        "  #expected = mae[index].reshape(8,8)\n",
        "  #predicted = predictions[index].reshape(8,8)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  #plt.subplot(1, 2, 1)\n",
        "  #plt.imshow(expected)\n",
        "  #plt.title('Expected')\n",
        "  #plt.subplot(1, 2, 2)\n",
        "  #plt.imshow(predicted)\n",
        "  #plt.title('Predicted')\n",
        "  #plt.show()\n",
        "  return  mape, maes, mse, rmse, msle, predic_64, y_64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rcpnA3JXa6v"
      },
      "source": [
        "# **Ensemble Models**\n",
        "\n",
        "1.   Random Forest Regressor\n",
        "2.   Bagging Regressor\n",
        "3.   Extra Trees Regressor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k_4S0O1BkZo"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBBSXMq_avLa"
      },
      "source": [
        "June_date = []\n",
        "year = '2021'\n",
        "month = '6'\n",
        "for i in range(1,32):\n",
        "  d = month + '/' + str(i) +'/' + year\n",
        "  June_date.append(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGv2JyyVeVzM"
      },
      "source": [
        "total_dates = append(asarray(date), June_date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GWRM8kqeV7Q"
      },
      "source": [
        "date_3_months = total_dates[len(total_dates)-92:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G15YxKIgf80x"
      },
      "source": [
        "def predictions_3_month (predictions_June, predictions, date_3_months, cols_o, name,i):\n",
        "    Apr_May_prediction = predictions[len(predictions)-61:,:]\n",
        "    Apr_May_June_pred = append(Apr_May_prediction, predictions_June, axis=0)\n",
        "    Apr_May_June_NO2_pred = DataFrame(Apr_May_June_pred, columns = [cols_o])\n",
        "    Apr_May_June_NO2_pred['date'] = date_3_months[0:len(date_3_months)-1]\n",
        "    Apr_May_June_NO2_a = asarray(Apr_May_June_NO2_pred)\n",
        "    pyplot.plot(date_3_months[0:len(date_3_months)-16], Apr_May_June_NO2_a[0:len(Apr_May_June_NO2_a)-15 ,i], marker='o', ms=4, label='Predicted')\n",
        "    pyplot.plot(dates_May_Apr[0:len(dates_May_Apr)-15], y_a[len(y_a)-46:,i], marker='o', ms=4,label='Expected')\n",
        "    pyplot.xticks(fontsize=13, rotation=90)\n",
        "    pyplot.xlabel('Date')\n",
        "    pyplot.ylabel('Nitrogen Dioxide (ug/m^3)')\n",
        "    pyplot.legend(fontsize=15)\n",
        "    pyplot.title(name, fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "\n",
        "    axes = pyplot.gca()\n",
        "    axes.xaxis.label.set_size(15)\n",
        "    axes.yaxis.label.set_size(15)\n",
        "\n",
        "    fig = pyplot.gcf()\n",
        "    fig.set_size_inches(23, 5)\n",
        "    return Apr_May_June_NO2_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pse4Hfgm2N_Y"
      },
      "source": [
        "data_x = series_to_supervised(values, 30, 15)\n",
        "cols = data_x.columns\n",
        "mape, mae, mse, rmse, msle, predictions, y_a = walk_forward_validation(data_x, 'Extra Trees Regressor', index = 249, model = ExtraTreesRegressor(n_estimators=24, max_depth=18))\n",
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Extra Trees Regressor', index = 249, model  = ExtraTreesRegressor(n_estimators=24, max_depth=18))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RciWDEgOMFFG"
      },
      "source": [
        "predictions_extra = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o,'Extra Trees', i=30)\n",
        "errors['Extra Trees']['MAE']=mae\n",
        "errors['Extra Trees']['MSE']=mse\n",
        "errors['Extra Trees']['RMSE']=rmse\n",
        "errors['Extra Trees']['MLSE']=msle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4iLe_Zs3MUI"
      },
      "source": [
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Extra Trees Regressor', index = 249, model  = ExtraTreesRegressor(n_estimators=24, max_depth=18))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FZVkG5D6LJu"
      },
      "source": [
        "predictions_extra = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o, 'Extra Trees Regressor')\n",
        "predictions_extra.to_csv('predictions_3_months_extra_trees.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsrjOrfhcQRa"
      },
      "source": [
        "values.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0IiDwK0B930"
      },
      "source": [
        "data_x = series_to_supervised(values, 30, 15)\n",
        "cols = data_x.columns\n",
        "mape, mae, mse, rmse, msle, predictions, y_a = walk_forward_validation(data_x, 'Bagging Regressor', index = 298, model = BaggingRegressor(n_estimators=2 ))\n",
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Bagging Regressor', index = 249, model = BaggingRegressor(n_estimators=2))\n",
        "predictions_bagging = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o, 'Bagging Regressor', 30)\n",
        "predictions_bagging.to_csv('NO2_predictions_June_bagging.csv')\n",
        "errors['Bagging']['MAE']=mae\n",
        "errors['Bagging']['MSE']=mse\n",
        "errors['Bagging']['RMSE']=rmse\n",
        "errors['Bagging']['MLSE']=msle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1afuh2pRNn9"
      },
      "source": [
        "predictions_June = predictions_no_walk(values, data, 'Bagging Regressor', index = 249, model = BaggingRegressor(n_estimators=10))\n",
        "predictions_bagging = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o, 'Bagging Regressor')\n",
        "predictions_bagging.to_csv('NO2_predictions_June_bagging.csv')\n",
        "errors['Bagging']['MAE']=mae\n",
        "errors['Bagging']['MSE']=mse\n",
        "errors['Bagging']['RMSE']=rmse\n",
        "errors['Bagging']['MLSE']=msle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1nRTI3i5EW1"
      },
      "source": [
        "data_x = series_to_supervised(values, 30, 15)\n",
        "cols = data_x.columns\n",
        "mape, mae, mse, rmse, msle, predictions, y = walk_forward_validation(data_x, 'Random Forest Regressor', index = 297, model=RandomForestRegressor(n_estimators=2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ryj3emOPhD"
      },
      "source": [
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Random Forest Regressor', index = 249, model = RandomForestRegressor(n_estimators=2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDUwdKkecjC2"
      },
      "source": [
        "predictions_RF = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o, 'Random Forest', i = 30)\n",
        "predictions_RF.to_csv('NO2_predictions_June_Random_Forest.csv')\n",
        "errors['Random Forest']['MAE']=mae\n",
        "errors['Random Forest']['MSE']=mse\n",
        "errors['Random Forest']['RMSE']=rmse\n",
        "errors['Random Forest']['MLSE']=msle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVeRicJT8WKj"
      },
      "source": [
        "# **Linear Models** \n",
        "\n",
        "1.   Linear Regression\n",
        "2.   Elastic Net Regression\n",
        "3.   Ridge Linear Regression\n",
        "4.   Lasso Linear Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o09cdpGBBMRM"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import RidgeCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-iGvpiqsGkR"
      },
      "source": [
        "#data_x = series_to_supervised(values, 3, 1)\n",
        "#cols = data_x.columns\n",
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "mape, mae, mse, rmse, msle, predictions, y_a = walk_forward_validation(data, 'Linear Regressor', index = 200, model = LinearRegression())\n",
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Extra Trees Regressor', index = 249, model = LinearRegression())\n",
        "predictions_linear = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o, 'Linear Regressor', 30)\n",
        "predictions_linear.to_csv('NO2_predictions_June_Linear_Regression.csv')\n",
        "errors['Linear Regressor']['MAE']=mae\n",
        "errors['Linear Regressor']['MSE']=mse\n",
        "errors['Linear Regressor']['RMSE']=rmse\n",
        "errors['Linear Regressor']['MLSE']=msle\n",
        "\n",
        "#fig.savefig('test2png.png', dpi=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--P-V-PIZ5AU"
      },
      "source": [
        "data_x = series_to_supervised(values, 30, 15)\n",
        "cols = data_x.columns\n",
        "mape, mae, mse, rmse, msle, predictions, y = walk_forward_validation(data_x, 'Lasso', index = 300, model = Lasso())\n",
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Extra Trees Regressor', index = 249, model = Lasso())\n",
        "predictions_lasso = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o, 'Lasso', i =30)\n",
        "errors['Lasso']['MAE']=mae\n",
        "errors['Lasso']['MSE']=mse\n",
        "errors['Lasso']['RMSE']=rmse\n",
        "errors['Lasso']['MLSE']=msle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IascpKDT2Nrt"
      },
      "source": [
        "data_x = series_to_supervised(values, 30, 15)\n",
        "cols = data_x.columns\n",
        "mape, mae, mse, rmse, msle, predictions, y = walk_forward_validation(data_x, 'Elastic Net', index = 300, model = ElasticNet())\n",
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Extra Trees Regressor', index = 249, model = ElasticNet())\n",
        "predictions_elastic = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o, name = 'Elastic Net', i =30)\n",
        "errors['Elastic Net']['MAE']=mae\n",
        "errors['Elastic Net']['MSE']=mse\n",
        "errors['Elastic Net']['RMSE']=rmse\n",
        "errors['Elastic Net']['MLSE']=msle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy_XE_EW2N1o"
      },
      "source": [
        "data_x = series_to_supervised(values, 30, 15)\n",
        "cols = data_x.columns\n",
        "mape, mae, mse, rmse, msle, predictions, y = walk_forward_validation(data_x, 'Ridge CV', index = 160, model = RidgeCV())\n",
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Extra Trees Regressor', index = 249, model = RidgeCV())\n",
        "predictions_ridge = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o,'Ridge CV', 20)\n",
        "errors['Ridge']['MAE']=mae\n",
        "errors['Ridge']['MSE']=mse\n",
        "errors['Ridge']['RMSE']=rmse\n",
        "errors['Ridge']['MLSE']=msle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SEEsDVeAR5O"
      },
      "source": [
        "# **Non Linear Models**\n",
        "\n",
        "1.   K Neighbour Regressor\n",
        "2.   Decision Trees Regressor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJooTuCmuBxr"
      },
      "source": [
        "data_x = series_to_supervised(values, 30, 15)\n",
        "cols = data_x.columns\n",
        "mape, mae, mse, rmse, msle, predictions, y = walk_forward_validation(data_x, 'Decision Tree Regressor', index = 300, model = DecisionTreeRegressor( max_depth = 16))\n",
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Extra Trees Regressor', index = 249, model = DecisionTreeRegressor( max_depth = 16))\n",
        "predictions_decision_trees = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o, 'Decision Tree', 30)\n",
        "predictions_decision_trees.to_csv('predictions_three_months_decision_trees.csv')\n",
        "errors['Decision Tree']['MAE']=mae\n",
        "errors['Decision Tree']['MSE']=mse\n",
        "errors['Decision Tree']['RMSE']=rmse\n",
        "errors['Decision Tree']['MLSE']=msle\n",
        "\n",
        "#predicted = predictions[:,3]\n",
        "#expected = y[:,3]\n",
        "#pyplot.plot(dates_May_Apr, y[len(predictions)-61:,3], label='Expected')\n",
        "#pyplot.plot(dates_May_Apr, predictions[len(predictions)-61:,3], label='Predicted')\n",
        "#plt.xticks(rotation=90)\n",
        "#pyplot.xlabel('Date')\n",
        "#pyplot.ylabel('Nitrogen Dioxide (ug/m^3)')\n",
        "#pyplot.legend()\n",
        "\n",
        "#fig.savefig('test2png.png', dpi=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30z7UbePn4c5"
      },
      "source": [
        "predicted = predictions[1:,17]\n",
        "expected = y[1:,17]\n",
        "pyplot.plot(predicted, label='Expected')\n",
        "pyplot.plot(expected, label='Predicted')\n",
        "plt.xticks(rotation=90)\n",
        "pyplot.xlabel('Date')\n",
        "pyplot.ylabel('Nitrogen Dioxide (ug/m^3)')\n",
        "pyplot.legend()\n",
        "pyplot.title('Decision Tree Regressor')\n",
        "\n",
        "\n",
        "\n",
        "print(mean_absolute_percentage_error(y[len(predictions)-61:,9],predictions[len(predictions)-61:,9]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pihVMvhtrkxj"
      },
      "source": [
        "data_x = series_to_supervised(values, 30, 15)\n",
        "cols = data_x.columns\n",
        "mape, mae, mse, rmse, msle, predictions, y_a = walk_forward_validation(data_x, 'K Neighbour Regressor', index = 140, model = KNeighborsRegressor(n_neighbors=100))\n",
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "predictions_June = predictions_no_walk(values, data, 'Extra Trees Regressor', index = 249, model = KNeighborsRegressor(n_neighbors=100))\n",
        "predictions_KNN = predictions_3_month (predictions_June[1:,:], predictions, date_3_months, cols_o, 'K Neighbour Regressor', 30)\n",
        "errors['K Neighnours']['MAE']=mae\n",
        "errors['K Neighnours']['MSE']=mse\n",
        "errors['K Neighnours']['RMSE']=rmse\n",
        "errors['K Neighnours']['MLSE']=msle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK1JgADXfmO-"
      },
      "source": [
        "# **Deep Learning Models : CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dzLFj4LYohM"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif out_end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn asarray(X), asarray(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTUgKkcAaxG2"
      },
      "source": [
        "X, Y = split_sequences(values, 30, 15)\n",
        "print(X.shape, Y.shape)\n",
        "X_train, y_train, x_test, y = X[0:int(0.98*len(X)),:,:],Y[0:int(0.98*len(X)),:,:],X[int(0.98*len(X)):,:,:],Y[int(0.98*len(X)):,:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ILRqvrY2Qo"
      },
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "n_output = Y.shape[1] * Y.shape[2]\n",
        "Y = Y.reshape((Y.shape[0], n_output))\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "n_steps_in, n_steps_out = 30, 15\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmzKbl-BFjpj"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, input_shape=(n_steps_in, n_features)))\n",
        "model.add(LeakyReLU(alpha=0.05))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50))\n",
        "model.add(LeakyReLU(alpha=0.05))\n",
        "#model.add(Dense(10))\n",
        "#model.add(LeakyReLU(alpha=0.05))\n",
        "model.add(Dense(n_output))\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "model.fit(X_train, y_train.reshape((y_train.shape[0], n_output)), epochs=700, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-qNlG9VPWAA"
      },
      "source": [
        "# demonstrate prediction\n",
        "predictions=[]\n",
        "for i in range(0,len(x_test)):\n",
        "  x_input = x_test[i,:,:]\n",
        "  x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "  yhat = model.predict(x_input, verbose=0)\n",
        "  predictions.append(yhat)\n",
        "predictions=asarray(predictions).reshape(len(y), y.shape[1], y.shape[2])\n",
        "predictions = predictions.reshape(len(predictions)*15,64)\n",
        "y = y.reshape(len(y)*15, 64)\n",
        "predictions_June_cnn = []\n",
        "june = x_test[len(x_test)-1,:,:]\n",
        "for i in range(0,2):\n",
        "  x_input = june\n",
        "  x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "  yhat = model.predict(x_input, verbose=0)\n",
        "  june = append(x_test[len(x_test)-1,15:30,:],yhat.reshape(15,64), axis=0)\n",
        "  predictions_June_cnn.append(yhat)\n",
        "\n",
        "predictions_June_cnn = asarray(predictions_June_cnn)\n",
        "predictions_June_1 = predictions_June_cnn[0,:,:].reshape(15,64)\n",
        "predictions_June_2 = predictions_June_cnn[1,:,:].reshape(15,64)\n",
        "predictions_june = append(predictions_June_1, predictions_June_2 , axis=0)\n",
        "\n",
        "maes = mean_absolute_error(y, predictions)\n",
        "mse = mean_squared_error(y, predictions)\n",
        "rmse = sqrt(mse)\n",
        "mape = mean_absolute_percentage_error(y,predictions)\n",
        "name = 'CNN'\n",
        "print(name,  ':Mean Absolute Error (Nitrogen Dioxide):', maes)\n",
        "print(name,  ':Mean Squared Error (Nitrogen Dioxide):', mse)\n",
        "print(name,  ':Root Mean Squared Error (Nitrogen Dioxide):', rmse)\n",
        "print(name,  ':Mean Absolute Percentage Error (Nitrogen Dioxide):', mape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mt9ejSpenl9"
      },
      "source": [
        "cnn_3_months =  predictions_3_month (predictions_june, predictions, date_3_months, cols_o, 'CNN', 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multilayer Perceptron (MLP)**"
      ],
      "metadata": {
        "id": "40fscfbkJymk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q5DhH9yFz7R"
      },
      "source": [
        "X, Y = split_sequences(values, 30, 15)\n",
        "print(X.shape, Y.shape)\n",
        "X_train, y_train, x_test, y = X[0:int(0.98*len(X)),:,:],Y[0:int(0.98*len(X)),:,:],X[int(0.98*len(X)):,:,:],Y[int(0.98*len(X)):,:,:]\n",
        "n_input = X_train.shape[1] * X_train.shape[2]\n",
        "x_t = X_train.reshape((X_train.shape[0], n_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K01s0OpUJFXO"
      },
      "source": [
        "x_t.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkScP0zuF_it"
      },
      "source": [
        "n_output = y_train.shape[1]*y_train.shape[2]\n",
        "print(n_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paa3LvODMMX4"
      },
      "source": [
        "y_train = y_train.reshape(len(y_train), 15*64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcfwpKbMOqm0"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC3t3ZFWEiRw"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(150, input_dim=n_input))\n",
        "model.add(LeakyReLU(alpha=0.04))\n",
        "model.add(Dense(100, input_dim=n_input))\n",
        "model.add(LeakyReLU(alpha=0.04))\n",
        "model.add(Dense(100, input_dim=n_input))\n",
        "model.add(LeakyReLU(alpha=0.04))\n",
        "model.add(Dense(n_output))\n",
        "model.compile(optimizer='adam', loss='mape')\n",
        "model.fit(x_t, y_train, epochs=30, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bR0rreEPEzL"
      },
      "source": [
        "model.fit(x_t, y_train, epochs=300, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7eDK6XdEiZO"
      },
      "source": [
        "# demonstrate prediction\n",
        "X, Y = split_sequences(values, 30, 15)\n",
        "print(X.shape, Y.shape)\n",
        "X_train, y_train, x_test, y = X[0:int(0.98*len(X)),:,:],Y[0:int(0.98*len(X)),:,:],X[int(0.98*len(X)):,:,:],Y[int(0.98*len(X)):,:,:]\n",
        "predictions=[]\n",
        "for i in range(0,len(x_test)):\n",
        "  x_input = x_test[i,:,:]\n",
        "  x_input = x_input.reshape((1,n_input))\n",
        "  yhat = model.predict(x_input, verbose=0)\n",
        "  predictions.append(yhat)\n",
        "predictions=asarray(predictions).reshape(len(y), y.shape[1], y.shape[2])\n",
        "predictions = predictions.reshape(len(predictions)*15,64)\n",
        "y = y.reshape(len(y)*15, 64)\n",
        "predictions_June_cnn = []\n",
        "june = x_test[len(x_test)-1,:,:]\n",
        "for i in range(0,2):\n",
        "  x_input = june\n",
        "  x_input = x_input.reshape((1,n_input))\n",
        "  yhat = model.predict(x_input, verbose=0)\n",
        "  june = append(x_test[len(x_test)-1,15:30,:],yhat.reshape(15,64), axis=0)\n",
        "  predictions_June_cnn.append(yhat)\n",
        "\n",
        "predictions_June_cnn = asarray(predictions_June_cnn)\n",
        "predictions_June_1 = predictions_June_cnn[0,:,:].reshape(15,64)\n",
        "predictions_June_2 = predictions_June_cnn[1,:,:].reshape(15,64)\n",
        "predictions_june = append(predictions_June_1, predictions_June_2 , axis=0)\n",
        "\n",
        "maes = mean_absolute_error(y, predictions)\n",
        "mse = mean_squared_error(y, predictions)\n",
        "rmse = sqrt(mse)\n",
        "mape = mean_absolute_percentage_error(y,predictions)\n",
        "name = 'MLP'\n",
        "print(name,  ':Mean Absolute Error (Nitrogen Dioxide):', maes)\n",
        "print(name,  ':Mean Squared Error (Nitrogen Dioxide):', mse)\n",
        "print(name,  ':Root Mean Squared Error (Nitrogen Dioxide):', rmse)\n",
        "print(name,  ':Mean Absolute Percentage Error (Nitrogen Dioxide):', mape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-_KVPP6EicC"
      },
      "source": [
        "mlp_3_months =  predictions_3_month (predictions_june, predictions, date_3_months, cols_o, 'MLP', 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfBeKv_HETYb"
      },
      "source": [
        "# **ConvLSTMs**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yajPqI2VZiSf"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpdlgEEPla7X"
      },
      "source": [
        "data = series_to_supervised(values, 30, 15)\n",
        "cols = data.columns\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMZN9HwMnpwC"
      },
      "source": [
        "data_x = data.iloc[:][cols[0:30*64]]\n",
        "data_y = data.iloc[:][cols[30*64:]]\n",
        "print(data_x.shape, data_y.shape)\n",
        "data_x = asarray(data_x)\n",
        "data_y = asarray(data_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQq64rlmpBuC"
      },
      "source": [
        "data_x_=[]\n",
        "data_y_=[]\n",
        "for i in range(0,len(data_x)):\n",
        "  d = data_x[i].reshape(30,1,8,8)\n",
        "  ya = data_y[i].reshape(15,1,8,8)\n",
        "  data_x_.append(d)\n",
        "  data_y_.append(ya)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc0UA_6lp-Dz"
      },
      "source": [
        "input_sequence = asarray(data_x_)\n",
        "output_sequence = asarray(data_y_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXrwsLteYxCG"
      },
      "source": [
        "train_x = input_sequence[0:int(0.8*(input_sequence.shape[0]))]\n",
        "train_y = output_sequence[0:int(0.8*(input_sequence.shape[0]))]\n",
        "train_y.shape\n",
        "print(train_x.shape, train_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAbL2Q3ZYxEp"
      },
      "source": [
        "test_x = input_sequence[int(0.8*(input_sequence.shape[0])):]\n",
        "test_y = output_sequence[int(0.8*(input_sequence.shape[0])):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5VEA3J2YxG7"
      },
      "source": [
        "seq = keras.Sequential(\n",
        "    [   keras.Input(\n",
        "            shape=(30,1,8,8)\n",
        "        ),  \n",
        "        layers.ConvLSTM2D(\n",
        "            filters=1, kernel_size=(5, 5),recurrent_activation='hard_sigmoid',\n",
        "                         kernel_initializer='glorot_uniform', padding=\"same\", data_format = 'channels_first', return_sequences=True\n",
        "        ),\n",
        "        layers.LeakyReLU(alpha=0.3),\n",
        "        #layers.BatchNormalization(),\n",
        "        #layers.ConvLSTM2D(\n",
        "        #    filters=1, kernel_size=(2, 2), recurrent_activation='hard_sigmoid',\n",
        "        #                 kernel_initializer='glorot_uniform', padding=\"same\", data_format = 'channels_first', return_sequences=True\n",
        "        #),\n",
        "        #layers.LeakyReLU(alpha=0.3),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv3D(\n",
        "           filters=15, kernel_size=(3, 3, 3), padding=\"same\", data_format = 'channels_first'\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "seq.compile(loss=\"mape\", optimizer=opt, metrics=[tf.keras.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79AdvsxpYxJ2"
      },
      "source": [
        "seq.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTf7GvArY-LK"
      },
      "source": [
        "epochs = 150\n",
        "history  = seq.fit(\n",
        "    train_x[:],\n",
        "    train_y[:],\n",
        "    batch_size = 32,\n",
        "    epochs=epochs,\n",
        "    verbose=2,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZKtjJvpY-QO"
      },
      "source": [
        "seq.save('/content/drive/My Drive/FYP Models/regression_so2/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfgrFk3uY-TU"
      },
      "source": [
        "convlstm_model = keras.models.load_model('/content/drive/My Drive/FYP Models/regression_so2/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUlRz2uZY-XB"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxPB6iEyY-ZY"
      },
      "source": [
        "plt.plot(history.history['mean_absolute_error'])\n",
        "plt.plot(history.history['val_mean_absolute_error'])\n",
        "plt.title('Mean Squared Error: Nitrogen Dioxide')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ESAHUBCZLJu"
      },
      "source": [
        "predictions = []\n",
        "for i in range(0,len(test_x)):\n",
        "    pred = convlstm_model.predict(test_x[i].reshape(1,30,1,8,8))\n",
        "    predictions.append(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGbF_LJXI2WK"
      },
      "source": [
        "predictions_J = []\n",
        "june = test_x[-1]\n",
        "for i in range(0,2):\n",
        "    pred = convlstm_model.predict(june.reshape(1,30,1,8,8))\n",
        "    pred = asarray(pred)\n",
        "    pred = pred.reshape(15,1,8,8)\n",
        "    june = append(test_x[len(test_x)-1,15:,:,:,:], pred, axis = 0)\n",
        "    predictions_J.append(pred.reshape(15,64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP3rfnANi-nD"
      },
      "source": [
        "predictions = asarray(predictions)\n",
        "test_y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz-syNAhOFwa"
      },
      "source": [
        "predictions_j = asarray(predictions_J).reshape(30,64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdY0DxqhivOU"
      },
      "source": [
        "predictions = predictions.reshape(len(predictions)*15, 64)\n",
        "#test_y = test_y.reshape(len(test_y)*15, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i45JD_eZLPW"
      },
      "source": [
        "mae = mean_absolute_error(test_y, predictions)\n",
        "mse = mean_squared_error(test_y, predictions)\n",
        "rmse = sqrt(mse)\n",
        "mape = mean_absolute_percentage_error(test_y, predictions)\n",
        "print('Mean Absolute Error:', mae)\n",
        "print('Mean Squared Error', mse)\n",
        "print('Root Mean Squared Error', rmse)\n",
        "print('MAPE:', mape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_XUzwBtlJvK"
      },
      "source": [
        "convlstm_3_months =  predictions_3_month (predictions_j, predictions, date_3_months, cols_o, 'ConvLSTMs', 30)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}